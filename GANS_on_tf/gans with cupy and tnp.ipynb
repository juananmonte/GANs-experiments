{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f39e8e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T08:46:07.233607Z",
     "start_time": "2021-06-28T08:46:03.047226Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mlp\n",
    "import random\n",
    "# import cv2\n",
    "#import h5py\n",
    "from pathlib import Path\n",
    "\n",
    "#import cupy as cp\n",
    "import tensorflow.experimental.numpy as tnp\n",
    "import numpy as np\n",
    "from numpy import expand_dims\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy import asarray\n",
    "# from cupy.random import randn\n",
    "from numpy.random import randint\n",
    "from numpy import savez_compressed\n",
    "from numpy import load \n",
    "\n",
    "#from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras.layers import Conv2DTranspose\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import load_img \n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import Dropout \n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import plot_model\n",
    "#from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9970b16c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T06:17:41.272305Z",
     "start_time": "2021-06-28T06:17:41.264153Z"
    }
   },
   "outputs": [],
   "source": [
    "train = 'E:/UCF_Crimes/train_frames/' \n",
    "test = 'E:/UCF_Crimes/test_frames_label/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90581dc4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T06:38:36.117976Z",
     "start_time": "2021-06-28T06:17:42.193389Z"
    }
   },
   "outputs": [],
   "source": [
    "images_train= os.listdir(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1eab82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T06:38:46.373346Z",
     "start_time": "2021-06-28T06:38:37.112704Z"
    }
   },
   "outputs": [],
   "source": [
    "categories_train = []\n",
    "\n",
    "for filename in images_train:\n",
    "    category = filename.split('_')[0] #el split, 3 elementos. el 0 es Dog or Cat\n",
    "    if category == 'Abuse':\n",
    "        categories_train.append(1)\n",
    "    elif category == 'Arrest':\n",
    "        categories_train.append(2)\n",
    "    elif category == 'Arson':\n",
    "        categories_train.append(3)\n",
    "    elif category == 'Assault':\n",
    "        categories_train.append(4)\n",
    "    elif category == 'Burglary':\n",
    "        categories_train.append(5)\n",
    "    elif category == 'Explosion':\n",
    "        categories_train.append(6)\n",
    "    elif category == 'Fighting':\n",
    "        categories_train.append(7)\n",
    "    elif category == 'RoadAccidents':\n",
    "        categories_train.append(8)\n",
    "    elif category == 'Robbery':\n",
    "        categories_train.append(9)\n",
    "    elif category == 'Shooting':\n",
    "        categories_train.append(10)\n",
    "    elif category == 'Shoplifting':\n",
    "        categories_train.append(11)\n",
    "    elif category == 'Stealing':\n",
    "        categories_train.append(12)\n",
    "    elif category == 'NormalVideos':\n",
    "        categories_train.append(13)\n",
    "    elif category == 'Vandalism':\n",
    "        categories_train.append(14)\n",
    "    else:\n",
    "        categories.append(0)\n",
    "\n",
    "df_train = pd.DataFrame({\n",
    "    'filename': images_train,\n",
    "    'category': categories_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3984d28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T06:38:48.351518Z",
     "start_time": "2021-06-28T06:38:48.308796Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf90dd3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T06:38:50.297572Z",
     "start_time": "2021-06-28T06:38:50.209256Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train.category.value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534dc982",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T06:38:52.233109Z",
     "start_time": "2021-06-28T06:38:52.150983Z"
    }
   },
   "outputs": [],
   "source": [
    "a = df_train['category'].value_counts()\n",
    "a = pd.DataFrame(a)\n",
    "a.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75a2352",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T06:38:54.142265Z",
     "start_time": "2021-06-28T06:38:54.130592Z"
    }
   },
   "outputs": [],
   "source": [
    "mlp.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6381f5c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T06:38:56.754039Z",
     "start_time": "2021-06-28T06:38:56.002196Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,7))\n",
    "sns.barplot(x = a['index'], y=a['category'], palette= 'Spectral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9601be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T06:38:58.983673Z",
     "start_time": "2021-06-28T06:38:58.611610Z"
    }
   },
   "outputs": [],
   "source": [
    "#See a random train image\n",
    "sample = random.choice(images_train)\n",
    "rando = image.load_img(train+ \"/\" + sample) \n",
    "plt.imshow(rando)\n",
    "plt.grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b7aaa6",
   "metadata": {},
   "source": [
    "### Test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14e3aee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T06:44:08.816356Z",
     "start_time": "2021-06-28T06:39:00.834455Z"
    }
   },
   "outputs": [],
   "source": [
    "images_test = os.listdir(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab7bedf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T06:44:13.082291Z",
     "start_time": "2021-06-28T06:44:10.800536Z"
    }
   },
   "outputs": [],
   "source": [
    "categories_test = []\n",
    "\n",
    "for filename in images_test:\n",
    "    category = filename.split('_')[0] #el split, 3 elementos. el 0 es Dog or Cat\n",
    "    if category == 'Abuse':\n",
    "        categories_test.append(1)\n",
    "    elif category == 'Arrest':\n",
    "        categories_test.append(2)\n",
    "    elif category == 'Arson':\n",
    "        categories_test.append(3)\n",
    "    elif category == 'Assault':\n",
    "        categories_test.append(4)\n",
    "    elif category == 'Burglary':\n",
    "        categories_test.append(5)\n",
    "    elif category == 'Explosion':\n",
    "        categories_test.append(6)\n",
    "    elif category == 'Fighting':\n",
    "        categories_test.append(7)\n",
    "    elif category == 'RoadAccidents':\n",
    "        categories_test.append(8)\n",
    "    elif category == 'Robbery':\n",
    "        categories_test.append(9)\n",
    "    elif category == 'Shooting':\n",
    "        categories_test.append(10)\n",
    "    elif category == 'Shooplifting':\n",
    "        categories_test.append(11)\n",
    "    elif category == 'Stealing':\n",
    "        categories_test.append(12)\n",
    "    elif category == 'NormalVideos':\n",
    "        categories_test.append(13)\n",
    "    elif category == 'Vandalism':\n",
    "        categories_test.append(14)\n",
    "    else:\n",
    "        categories_test.append(0)\n",
    "\n",
    "df_test = pd.DataFrame({\n",
    "    'filename': images_test,\n",
    "    'category': categories_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdb241e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T06:44:15.043918Z",
     "start_time": "2021-06-28T06:44:15.006426Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fddbe5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T06:44:17.373041Z",
     "start_time": "2021-06-28T06:44:17.185720Z"
    }
   },
   "outputs": [],
   "source": [
    "#See a random test image\n",
    "sample = random.choice(images_test)\n",
    "rando = image.load_img(test+ \"/\" + sample) \n",
    "plt.imshow(rando)\n",
    "plt.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63678c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T06:44:19.362996Z",
     "start_time": "2021-06-28T06:44:19.338880Z"
    }
   },
   "outputs": [],
   "source": [
    "b = df_test['category'].value_counts()\n",
    "b = pd.DataFrame(b) \n",
    "b.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27b64c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T06:44:22.032348Z",
     "start_time": "2021-06-28T06:44:21.483759Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,7))\n",
    "sns.barplot(x = b['index'], y=b['category'], palette= 'Spectral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047c23ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T07:22:40.932242Z",
     "start_time": "2021-06-28T07:22:40.919218Z"
    }
   },
   "outputs": [],
   "source": [
    "n_samples=50\n",
    "n_classes=14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745e1ce7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T08:45:11.529877Z",
     "start_time": "2021-06-28T07:22:46.813646Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for n in range(0, n_samples+1):\n",
    "    X_list, y_list = list(), list()\n",
    "    images = train_generator[n][0]\n",
    "    labels = tnp.array(change_to_right(train_generator[n][1])) #tf.convert_to_tensor() va antes de todo\n",
    "    n_per_class = int(10000 / n_classes)\n",
    "    for i in range(1, 15):\n",
    "    #filter images by their respective labels\n",
    "        X_with_class = images[labels == i]\n",
    "    # choose random instances\n",
    "        ix = randint(0, len(X_with_class), n_per_class)\n",
    "    # add each group of images to a list to train\n",
    "        [X_list.append(X_with_class[j]) for j in ix]\n",
    "        [y_list.append(i) for j in ix]\n",
    "    print(n)\n",
    "    filename1 = \"E:/UCF_Crimes/npz_120/crimes_120_{}.npz\".format(int(n))\n",
    "    savez_compressed(filename1, X_list, y_list)\n",
    "    print(\"Saved dataset: \", filename1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833235a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T07:16:18.769470Z",
     "start_time": "2021-06-28T07:16:18.384821Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = tnp.array(change_to_right(train_generator[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996e8309",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T07:16:27.553278Z",
     "start_time": "2021-06-28T07:16:27.536275Z"
    }
   },
   "outputs": [],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f103da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T08:48:36.468780Z",
     "start_time": "2021-06-28T08:48:36.462779Z"
    }
   },
   "outputs": [],
   "source": [
    "# #### combining the npz\n",
    "npz_path = \"E:/UCF_Crimes/npz_120/\"\n",
    "npz_list = os.listdir(npz_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b0c5c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T08:48:40.942765Z",
     "start_time": "2021-06-28T08:48:40.930796Z"
    }
   },
   "outputs": [],
   "source": [
    "npz_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3a45c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T08:48:53.175777Z",
     "start_time": "2021-06-28T08:48:53.156754Z"
    }
   },
   "outputs": [],
   "source": [
    "full_npz = [npz_path+fname for fname in npz_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55b453f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T08:49:01.247082Z",
     "start_time": "2021-06-28T08:49:01.233086Z"
    }
   },
   "outputs": [],
   "source": [
    "full_npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc449038",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T08:49:13.412917Z",
     "start_time": "2021-06-28T08:49:12.829512Z"
    }
   },
   "outputs": [],
   "source": [
    "data_all = [np.load(fname) for fname in full_npz] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3eaa76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T08:51:09.866744Z",
     "start_time": "2021-06-28T08:49:21.981428Z"
    }
   },
   "outputs": [],
   "source": [
    "images = list()\n",
    "images += [npz['arr_0'] for npz in data_all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7f280f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T08:51:58.244913Z",
     "start_time": "2021-06-28T08:51:58.223915Z"
    }
   },
   "outputs": [],
   "source": [
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831638c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-27T13:49:10.504625Z",
     "start_time": "2021-06-27T13:49:09.899817Z"
    }
   },
   "outputs": [],
   "source": [
    "# labels = list()\n",
    "# labels += [npz['arr_1'] for npz in data_all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5fd43b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T08:52:15.647551Z",
     "start_time": "2021-06-28T08:52:15.635556Z"
    }
   },
   "outputs": [],
   "source": [
    "images_all = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9839455f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T08:52:16.436551Z",
     "start_time": "2021-06-28T08:52:16.267553Z"
    }
   },
   "outputs": [],
   "source": [
    "for n in range(0, 13):\n",
    "    for i in images[n]:\n",
    "        images_all.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10638d4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T09:40:20.009339Z",
     "start_time": "2021-06-28T09:40:17.667715Z"
    }
   },
   "outputs": [],
   "source": [
    "filename1 = \"E:/UCF_Crimes/npz_120/crimes_images.npz\"\n",
    "savez_compressed(filename1, images_all)\n",
    "print(\"Saved dataset: \", filename1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a318234",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-27T11:35:03.242876Z",
     "start_time": "2021-06-27T11:35:03.236875Z"
    }
   },
   "outputs": [],
   "source": [
    "# labels_im = load(\"E:/UCF_Crimes/crimes_labels.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d56a3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-27T11:35:31.217310Z",
     "start_time": "2021-06-27T11:35:31.196312Z"
    }
   },
   "outputs": [],
   "source": [
    "# labels_im = labels_im['arr_0']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c58dc72",
   "metadata": {},
   "source": [
    "# Before all, define a custom activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b62880b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T14:51:04.130118Z",
     "start_time": "2021-06-24T14:51:04.119920Z"
    }
   },
   "outputs": [],
   "source": [
    "# custom activation function\n",
    "def custom_activation(output):\n",
    "    logexpsum = backend.sum(backend.exp(output), axis=-1, keepdims=True)\n",
    "    result = logexpsum / (logexpsum + 1.0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfebf0da",
   "metadata": {},
   "source": [
    "# Defining the models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03b5ada",
   "metadata": {},
   "source": [
    "#### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f21dda9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T14:51:12.538264Z",
     "start_time": "2021-06-24T14:51:12.507983Z"
    }
   },
   "outputs": [],
   "source": [
    "# define the standalone supervised and unsupervised discriminator models\n",
    "def define_discriminator(in_shape=(120, 120, 3), n_classes=14):\n",
    "# image input\n",
    "    in_image = Input(shape=in_shape)\n",
    "# downsample\n",
    "    fe = Conv2D(128, (3,3), strides=(2,2), padding='same')(in_image)\n",
    "    fe = LeakyReLU(alpha=0.2)(fe)\n",
    "# downsample\n",
    "    fe = Conv2D(128, (3,3), strides=(2,2), padding='same')(fe)\n",
    "    fe = LeakyReLU(alpha=0.2)(fe)\n",
    "# downsample\n",
    "    fe = Conv2D(128, (3,3), strides=(2,2), padding='same')(fe)\n",
    "    fe = LeakyReLU(alpha=0.2)(fe)\n",
    "# flatten feature maps\n",
    "    fe = Flatten()(fe)\n",
    "# dropout\n",
    "    fe = Dropout(0.4)(fe)\n",
    "# output layer nodes\n",
    "    fe = Dense(n_classes)(fe)\n",
    "# supervised output\n",
    "    c_out_layer = Activation('softmax')(fe)\n",
    "# define and compile supervised discriminator model\n",
    "    c_model = Model(in_image, c_out_layer)\n",
    "    c_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5), metrics=['accuracy'])\n",
    "# unsupervised output\n",
    "    d_out_layer = Lambda(custom_activation)(fe)\n",
    "# define and compile unsupervised discriminator model\n",
    "    d_model = Model(in_image, d_out_layer)\n",
    "    d_model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5))\n",
    "    return d_model, c_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d02d6f",
   "metadata": {},
   "source": [
    "#### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5a27f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-27T10:59:22.752197Z",
     "start_time": "2021-06-27T10:59:22.605653Z"
    }
   },
   "outputs": [],
   "source": [
    "# define the standalone generator model\n",
    "def define_generator(latent_dim):\n",
    "    # image generator input\n",
    "    in_lat = Input(shape=(latent_dim,))\n",
    "# foundation for 120x120 image (the 15*15 is the 1/8 of the size of the image. metric given by the book)\n",
    "    n_nodes = 128 * 15 * 15\n",
    "    gen = Dense(n_nodes)(in_lat)\n",
    "    gen = LeakyReLU(alpha=0.2)(gen)\n",
    "    gen = Reshape((15, 15, 128))(gen)\n",
    "    # upsample to 30x30\n",
    "    gen = Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')(gen)\n",
    "    gen = LeakyReLU(alpha=0.2)(gen)\n",
    "# upsample to 60x60\n",
    "    gen = Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')(gen)\n",
    "    gen = LeakyReLU(alpha=0.2)(gen)\n",
    "# #upsample to 120x120\n",
    "    gen = Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')(gen)\n",
    "    gen = LeakyReLU(alpha=0.2)(gen)\n",
    "# output\n",
    "    out_layer = Conv2D(3, (15, 15), activation='tanh', padding='same')(gen)\n",
    "# define model\n",
    "    model = Model(in_lat, out_layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b869dca6",
   "metadata": {},
   "source": [
    "```weight sharing is used where the output of the generator model is passed directly to the unsupervised discriminator model, and the weights of the discriminator are marked as not trainable.```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223ab28b",
   "metadata": {},
   "source": [
    "### combined generator and discriminator model (for updating the generator) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860e7938",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T14:51:28.977284Z",
     "start_time": "2021-06-24T14:51:28.964990Z"
    }
   },
   "outputs": [],
   "source": [
    "# define the combined generator and discriminator model, for updating the generator\n",
    "def define_gan(g_model, d_model):\n",
    "# make weights in the discriminator not trainable\n",
    "    d_model.trainable = False\n",
    "# connect image output from generator as input to discriminator\n",
    "    gan_output = d_model(g_model.output)\n",
    "# define gan model as taking noise and outputting a classification\n",
    "    model = Model(g_model.input, gan_output)\n",
    "# compile model\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb30eda",
   "metadata": {},
   "source": [
    "# select a supervised subset of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8416f224",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T01:43:59.803291Z",
     "start_time": "2021-06-24T01:43:59.790271Z"
    }
   },
   "outputs": [],
   "source": [
    "# def select_supervised_samples(dataset, n_samples=250, n_classes=14):\n",
    "#     X_list, y_list = list(), list()\n",
    "#     for n in range(0, 250+1): \n",
    "#         images = train_generator[n][0]\n",
    "#         a = cp.array(change_to_right(train_generator[n][1]))\n",
    "#         dlpack = a.toDlpack() \n",
    "#         labels = tf.experimental.dlpack.from_dlpack(dlpack) #convert to tensor\n",
    "#         n_per_class = int(250/14)\n",
    "#         for i in range(1, 15):\n",
    "#         #filter images by their respective labels\n",
    "#             X_with_class = images[labels == i]\n",
    "#         # choose random instances\n",
    "#             ix = tnp.random.randint(0, len(X_with_class), n_per_class)\n",
    "#         # add each group of images to a list to train\n",
    "#             [X_list.append(X_with_class[j]) for j in ix]\n",
    "#             [y_list.append(i) for j in ix]\n",
    "#         print(len(X_list))\n",
    "#         del images\n",
    "#         del labels\n",
    "#         del X_with_class\n",
    "#     return asarray(X_list), asarray(y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869cae8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T14:59:38.753629Z",
     "start_time": "2021-06-24T14:59:38.739604Z"
    }
   },
   "outputs": [],
   "source": [
    "# a = [2, 5, 7, 8, 9, 12, 13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6057d229",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T07:14:36.370325Z",
     "start_time": "2021-06-28T07:14:36.356297Z"
    }
   },
   "outputs": [],
   "source": [
    "def change_to_right(wrong_labels):\n",
    "    right_labels=[]\n",
    "    for x in wrong_labels:\n",
    "        for i in range(0,len(wrong_labels[0])):\n",
    "            if x[i]==1:\n",
    "                right_labels.append(i+1)\n",
    "    return right_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01e3e6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T15:23:34.050806Z",
     "start_time": "2021-06-24T15:23:34.029790Z"
    }
   },
   "outputs": [],
   "source": [
    "# def select_supervised_samples(dataset, n_samples=20, n_classes=7):\n",
    "#     X_list, y_list = list(), list()\n",
    "#     for n in range(0, n_samples+1):\n",
    "#         images = train_generator[n][0]\n",
    "#         labels = tnp.array(change_to_right(train_generator[n][1])) #tf.convert_to_tensor() va antes de todo\n",
    "#         n_per_class = int(n_samples / n_classes)\n",
    "#         for i in range(1, 15):\n",
    "#     #filter images by their respective labels\n",
    "#             X_with_class = images[labels == i]\n",
    "#     # choose random instances\n",
    "#             ix = randint(0, len(X_with_class), n_per_class)\n",
    "#     # add each group of images to a list to train\n",
    "#             [X_list.append(X_with_class[j]) for j in ix]\n",
    "#             [y_list.append(i) for j in ix]\n",
    "#         print(len(X_list))\n",
    "#     del images\n",
    "#     del labels\n",
    "#     del X_with_class\n",
    "#     return asarray(X_list), asarray(y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d425615",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T01:43:59.833615Z",
     "start_time": "2021-06-24T01:43:59.820901Z"
    }
   },
   "outputs": [],
   "source": [
    "#image = train_generator[1][0] #the first [] is the batch number (so 1000 batches of 3000 images)\n",
    "                              #the second [] is 0 for the images and 1 for the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a816e0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T01:43:59.849747Z",
     "start_time": "2021-06-24T01:43:59.833615Z"
    }
   },
   "outputs": [],
   "source": [
    "# label = train_generator[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1104ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T01:43:59.863708Z",
     "start_time": "2021-06-24T01:43:59.852748Z"
    }
   },
   "outputs": [],
   "source": [
    "# for i in range(6):\n",
    "#     plt.subplot(2,3,i+1)\n",
    "#     for x,y in train_generator:\n",
    "#         print(x.shape)\n",
    "#         plt.imshow(x[a])\n",
    "#         plt.xticks([])\n",
    "#         plt.yticks([])\n",
    "#         break\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d3892e",
   "metadata": {},
   "source": [
    "# Select random samples from the supervised dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e452f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T15:01:09.985564Z",
     "start_time": "2021-06-24T15:01:09.975509Z"
    }
   },
   "outputs": [],
   "source": [
    "# select real samples\n",
    "def generate_real_samples(dataset, n_samples):\n",
    "# split into images and labels\n",
    "   images = train_generator[n][0]\n",
    "   labels = tnp.array(change_to_right(train_generator[n][1]))\n",
    "# choose random instances\n",
    "    ix = randint(0, images.shape[0], n_samples)\n",
    "# select images and labels\n",
    "    X, labels = images[ix], labels[ix]\n",
    "# generate class labels\n",
    "    y = ones((n_samples, 1))\n",
    "    return [X, labels], y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc8e32c",
   "metadata": {},
   "source": [
    "# Select random samples from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bef04c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T15:01:16.684039Z",
     "start_time": "2021-06-24T15:01:16.672669Z"
    }
   },
   "outputs": [],
   "source": [
    "# select real samples\n",
    "def generate_real_samples2(dataset, n_samples):\n",
    "# split into images and labels\n",
    "    dataset = train_generator\n",
    "    i = randint(0, 1000)\n",
    "    images = dataset[i][0]\n",
    "    labels = tf.convert_to_tensor(tnp.array(change_to_right(train_generator[i][1])))\n",
    "# choose random instances\n",
    "    ix = randint(0, images.shape[0], n_samples)\n",
    "# select images and labels\n",
    "    X, labels = images[ix], labels[ix]\n",
    "# generate class labels\n",
    "    y = ones((n_samples, 1))\n",
    "    return [X, labels], y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc39b15",
   "metadata": {},
   "source": [
    "## generate points in latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854ad7ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T15:01:23.514679Z",
     "start_time": "2021-06-24T15:01:23.502896Z"
    }
   },
   "outputs": [],
   "source": [
    "# generate points in latent space as input for the generator\n",
    "def generate_latent_points(latent_dim, n_samples):\n",
    "# generate points in the latent space\n",
    "    z_input = randn(latent_dim * n_samples)\n",
    "# reshape into a batch of inputs for the network\n",
    "    z_input = z_input.reshape(n_samples, latent_dim)\n",
    "    return z_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9a411e",
   "metadata": {},
   "source": [
    "### Generate the fake images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f18ec0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T15:01:30.988000Z",
     "start_time": "2021-06-24T15:01:30.973923Z"
    }
   },
   "outputs": [],
   "source": [
    "# use the generator to generate n fake examples, with class labels\n",
    "def generate_fake_samples(generator, latent_dim, n_samples):\n",
    "# generate points in latent space\n",
    "    z_input = generate_latent_points(latent_dim, n_samples)\n",
    "# predict outputs\n",
    "    images = generator.predict(z_input)\n",
    "# create class labels\n",
    "    y = zeros((n_samples, 1))\n",
    "    return images, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f807a416",
   "metadata": {},
   "source": [
    "# save as a plot and save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ae7773",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T15:01:39.666089Z",
     "start_time": "2021-06-24T15:01:39.646541Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac5fd4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T15:01:48.947329Z",
     "start_time": "2021-06-24T15:01:48.920805Z"
    }
   },
   "outputs": [],
   "source": [
    "# generate samples and save as a plot and save the model\n",
    "def summarize_performance(step, g_model, c_model, latent_dim, dataset, n_samples=100):\n",
    "# prepare fake examples\n",
    "    X, _ = generate_fake_samples(g_model, latent_dim, n_samples)\n",
    "# scale from [-1,1] to [0,1]\n",
    "    X = (X + 1) / 2.0\n",
    "# plot images\n",
    "    for i in range(100):\n",
    "    # define subplot\n",
    "        #plt.subplot( 1 + i)\n",
    "    # turn off axis\n",
    "        plt.axis('off')\n",
    "    # plot raw pixel data\n",
    "        plt.imshow(X[i, :, :, 0])\n",
    "# save plot to file\n",
    "    filename1 = 'E:/UCF_Crimes/models results/generated_plot_%04d.png' % (step+1)\n",
    "    plt.savefig(filename1) \n",
    "    plt.close() \n",
    "# evaluate the classifier model\n",
    "    X = train_generator[step][0]\n",
    "    y = tf.convert_to_tensor(tnp.array(change_to_right(train_generator[step][1])))\n",
    "    _, acc = c_model.evaluate(X, y, verbose=0)\n",
    "    print('Classifier Accuracy: %.3f%%' % (acc * 100))\n",
    "# save the generator model\n",
    "    filename2 = 'E:/UCF_Crimes/models results/g_model_%04d.h5' % (step+1)\n",
    "    g_model.save(filename2)\n",
    "# save the classifier model\n",
    "    filename3 = 'E:/UCF_Crimes/models results/c_model_%04d.h5' % (step+1)\n",
    "    c_model.save(filename3)\n",
    "    print('>Saved: %s, %s, and %s' % (filename1, filename2, filename3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677a4af8",
   "metadata": {},
   "source": [
    "# Training the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236fc967",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T17:20:33.095347Z",
     "start_time": "2021-06-24T17:20:33.028368Z"
    }
   },
   "outputs": [],
   "source": [
    "#train the generator and discriminator\n",
    "def train(g_model, d_model, c_model, gan_model, dataset, latent_dim, n_epochs=30, n_batch=100):\n",
    "# select supervised dataset\n",
    "    X_sup, y_sup = select_supervised_samples(dataset)\n",
    "    print(X_sup.shape, y_sup.shape)\n",
    "# calculate the number of batches per training epoch\n",
    "    bat_per_epo = int(X_sup.shape[0]/n_batch)\n",
    "# calculate the number of training iterations\n",
    "    n_steps = bat_per_epo * n_epochs\n",
    "# calculate the size of half a batch of samples\n",
    "    half_batch = int(n_batch / 2)\n",
    "    print('n_epochs=%d, n_batch=%d, 1/2=%d, bat_per_e=%d, steps=%d' % (n_epochs, n_batch, half_batch, bat_per_epo, n_steps))\n",
    "# manually enumerate epochs\n",
    "    for i in range(n_steps):\n",
    "    # update supervised discriminator (c)\n",
    "        [Xsup_real, ysup_real], _ = generate_real_samples2([X_sup, y_sup], half_batch)\n",
    "        c_loss, c_acc = c_model.train_on_batch(Xsup_real, ysup_real)\n",
    "    # update unsupervised discriminator (d)\n",
    "        [X_real, _], y_real = generate_real_samples2(dataset, half_batch)\n",
    "        d_loss1 = d_model.train_on_batch(X_real, y_real)\n",
    "        X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "        d_loss2 = d_model.train_on_batch(X_fake, y_fake)\n",
    "    # update generator (g)\n",
    "        X_gan, y_gan = generate_latent_points(latent_dim, n_batch), ones((n_batch, 1))\n",
    "        g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
    "    # summarize loss on this batch\n",
    "        print('>%d, c[%.3f,%.0f], d[%.3f,%.3f], g[%.3f]' % (i+1, c_loss, c_acc*100, d_loss1, d_loss2, g_loss))\n",
    "    # evaluate the model performance every so often\n",
    "        if (i+1) % (bat_per_epo * 1) == 0:\n",
    "            summarize_performance(i, g_model, c_model, latent_dim, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db87584",
   "metadata": {},
   "source": [
    "## size of the latent space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb868ce7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-27T10:59:37.966238Z",
     "start_time": "2021-06-27T10:59:37.957239Z"
    }
   },
   "outputs": [],
   "source": [
    "latent_dim = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937f8f4e",
   "metadata": {},
   "source": [
    "##  create the discriminator models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a2284e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T15:02:21.057606Z",
     "start_time": "2021-06-24T15:02:15.918604Z"
    }
   },
   "outputs": [],
   "source": [
    "d_model, c_model = define_discriminator()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbf4011",
   "metadata": {},
   "source": [
    "## create the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302e35d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-27T10:59:46.092108Z",
     "start_time": "2021-06-27T10:59:40.052639Z"
    }
   },
   "outputs": [],
   "source": [
    "g_model = define_generator(latent_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d494eb98",
   "metadata": {},
   "source": [
    "## Create the GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e10dc1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T15:02:40.012533Z",
     "start_time": "2021-06-24T15:02:39.923615Z"
    }
   },
   "outputs": [],
   "source": [
    "gan_model = define_gan(g_model, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3e95e5",
   "metadata": {},
   "source": [
    "## load image data <<<<----- Preprocess first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88d0e0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T06:56:06.644566Z",
     "start_time": "2021-06-28T06:56:01.355039Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train['category'] = df_train['category'].astype('str')\n",
    "df_test['category'] = df_test['category'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74aab26b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T06:56:08.760646Z",
     "start_time": "2021-06-28T06:56:08.749372Z"
    }
   },
   "outputs": [],
   "source": [
    "train_datagen = image.ImageDataGenerator(\n",
    "    preprocessing_function= lambda x: (x - 127.5) / 127.5)\n",
    "\n",
    "#-----opcion 1 \n",
    "#(2 / 255) * x - 1) \n",
    "\n",
    "\n",
    "#----opcion 2\n",
    "\n",
    "# def prep_fn(img):\n",
    "#     img = img.astype(np.float32) / 255.0\n",
    "#     img = (img - 0.5) * 2\n",
    "#     return img\n",
    "\n",
    "# gen = ImageDataGenerator(\n",
    "#     preprocessing_function=prep_fn\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cc5e45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T07:21:53.964908Z",
     "start_time": "2021-06-28T07:17:15.817754Z"
    }
   },
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "                    df_train,\n",
    "                    'UCF_Crimes/train_frames/',\n",
    "                    x_col= 'filename',\n",
    "                    y_col= 'category',\n",
    "                    target_size= (120,120),\n",
    "                    class_mode= 'categorical',\n",
    "                    subset=\"training\",\n",
    "                    batch_size= 10000\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120bc2e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T01:52:53.204288Z",
     "start_time": "2021-06-24T01:52:53.190256Z"
    }
   },
   "outputs": [],
   "source": [
    "# #TEST_DATAGEN\n",
    "\n",
    "# train_datagen = image.ImageDataGenerator(\n",
    "#     preprocessing_function=lambda x: (x - 127.5) / 127.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7748c77e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T01:52:53.220268Z",
     "start_time": "2021-06-24T01:52:53.207255Z"
    }
   },
   "outputs": [],
   "source": [
    "# test_generator = train_datagen.flow_from_dataframe(\n",
    "#                     df_test,\n",
    "#                     'E:/UCF_Crimes/train_frames/',\n",
    "#                     x_col= 'filename',\n",
    "#                     y_col= 'category',\n",
    "#                     target_size= (120,120),\n",
    "#                     class_mode= 'categorical',\n",
    "#                     batch_size= 1000\n",
    "#                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70adfe54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T15:23:42.093808Z",
     "start_time": "2021-06-24T15:23:42.083773Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = train_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836e3f72",
   "metadata": {},
   "source": [
    "## train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1819e9",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-24T17:20:58.559Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train(g_model, d_model, c_model, gan_model, dataset, latent_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526ff39e",
   "metadata": {},
   "source": [
    "## Clear cache from this file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4310b2b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T04:20:48.880165Z",
     "start_time": "2021-06-24T01:17:55.135Z"
    }
   },
   "outputs": [],
   "source": [
    "# conda clean --all"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tf-latest)",
   "language": "python",
   "name": "tf-latest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
