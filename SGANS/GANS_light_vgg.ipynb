{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36a3e9b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T09:54:48.173148Z",
     "start_time": "2021-08-10T09:54:38.344095Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mlp\n",
    "import random\n",
    "from pathlib import Path\n",
    "import os\n",
    "import glob\n",
    "from operator import itemgetter\n",
    "\n",
    "import cv2\n",
    "import tensorflow.experimental.numpy as tnp\n",
    "import numpy as np\n",
    "from numpy import expand_dims\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy import asarray\n",
    "from numpy.random import randint\n",
    "from numpy import savez_compressed\n",
    "from numpy import load \n",
    "from numpy.random import randn\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import backend\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras.layers import Conv2DTranspose, MaxPooling2D, UpSampling2D\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import load_img \n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import Dropout \n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, Adagrad\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "#from tensorflow.keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a64ab1a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T09:58:08.291457Z",
     "start_time": "2021-08-04T09:58:08.262456Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "from tqdm import tqdm\n",
    "\n",
    "#backend.set_image_dim_ordering('th')\n",
    "#backend.image_data_format()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9b2314",
   "metadata": {},
   "source": [
    "# Load .npz files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8f1c024",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T10:10:26.251956Z",
     "start_time": "2021-08-10T10:10:26.236960Z"
    }
   },
   "outputs": [],
   "source": [
    "npy_file = 'E:/84 paper/'\n",
    "npy_file = os.listdir(npy_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "609a3b8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T10:10:33.627986Z",
     "start_time": "2021-08-10T10:10:33.608959Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Abuse001_x264_i3d.npy',\n",
       " 'Abuse001_x264_i3d_labels.npy',\n",
       " 'Abuse002_x264_i3d.npy',\n",
       " 'OneDrive_2021-08-10.zip']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npy_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "84c6eaa1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T10:11:00.083429Z",
     "start_time": "2021-08-10T10:11:00.069433Z"
    }
   },
   "outputs": [],
   "source": [
    "npy_files = np.load('E:/84 paper/Abuse001_x264_i3d_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f95e57c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T10:11:00.879747Z",
     "start_time": "2021-08-10T10:11:00.873747Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(171, 10, 2048)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npy_files.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80fb3fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48855cb9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T09:58:08.307457Z",
     "start_time": "2021-08-04T09:58:08.294457Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7199311a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T09:58:08.323455Z",
     "start_time": "2021-08-04T09:58:08.310458Z"
    }
   },
   "outputs": [],
   "source": [
    "# #### combining the npz\n",
    "npz_path = \"E:/UCF_Crimes/npz_120\"\n",
    "npz_list = os.listdir(npz_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba894b27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T09:58:08.339454Z",
     "start_time": "2021-08-04T09:58:08.325458Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['crimes_120_0.npz',\n",
       " 'crimes_120_1.npz',\n",
       " 'crimes_120_10.npz',\n",
       " 'crimes_120_11.npz',\n",
       " 'crimes_120_12.npz',\n",
       " 'crimes_120_2.npz',\n",
       " 'crimes_120_3.npz',\n",
       " 'crimes_120_4.npz',\n",
       " 'crimes_120_5.npz',\n",
       " 'crimes_120_6.npz',\n",
       " 'crimes_120_7.npz',\n",
       " 'crimes_120_8.npz',\n",
       " 'crimes_120_9.npz',\n",
       " 'crimes_1_25570.npz',\n",
       " 'crimes_1_25571.npz']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npz_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "450e63bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T09:58:08.355460Z",
     "start_time": "2021-08-04T09:58:08.342460Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('crimes_120_0.npz',\n",
       " 'crimes_120_1.npz',\n",
       " 'crimes_120_10.npz',\n",
       " 'crimes_120_4.npz')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_npz = itemgetter(0,1,2,7)(npz_list)\n",
    "full_npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f18cd03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T09:58:08.371456Z",
     "start_time": "2021-08-04T09:58:08.358457Z"
    }
   },
   "outputs": [],
   "source": [
    "# full_npz_val = itemgetter(4, 9)(npz_list)\n",
    "# full_npz_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5323292e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T09:58:08.387455Z",
     "start_time": "2021-08-04T09:58:08.374458Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('crimes_1_25570.npz', 'crimes_1_25571.npz')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_npz_test = itemgetter(13, 14)(npz_list)\n",
    "full_npz_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78fad893",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T09:58:08.403462Z",
     "start_time": "2021-08-04T09:58:08.392457Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['E:/UCF_Crimes/npz_120/crimes_120_0.npz',\n",
       " 'E:/UCF_Crimes/npz_120/crimes_120_1.npz',\n",
       " 'E:/UCF_Crimes/npz_120/crimes_120_10.npz',\n",
       " 'E:/UCF_Crimes/npz_120/crimes_120_4.npz']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_npz = [npz_path+ '/' + npz for npz in full_npz]\n",
    "full_npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2457c33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T09:58:08.419456Z",
     "start_time": "2021-08-04T09:58:08.407456Z"
    }
   },
   "outputs": [],
   "source": [
    "# full_npz_val = [npz_path+ '/' + npz for npz in full_npz_val]\n",
    "# full_npz_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cf065e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T09:58:08.435457Z",
     "start_time": "2021-08-04T09:58:08.422460Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['E:/UCF_Crimes/npz_120/crimes_1_25570.npz',\n",
       " 'E:/UCF_Crimes/npz_120/crimes_1_25571.npz']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_npz_test = [npz_path + '/' + npz for npz in full_npz_test]\n",
    "full_npz_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d3bb276",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T09:58:08.498453Z",
     "start_time": "2021-08-04T09:58:08.438460Z"
    }
   },
   "outputs": [],
   "source": [
    "data_all = [np.load(fname) for fname in full_npz] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5f94b81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T09:58:08.513455Z",
     "start_time": "2021-08-04T09:58:08.500457Z"
    }
   },
   "outputs": [],
   "source": [
    "# data_all_val = [np.load(fname) for fname in full_npz_val] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f923db96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T09:58:08.545459Z",
     "start_time": "2021-08-04T09:58:08.516457Z"
    }
   },
   "outputs": [],
   "source": [
    "data_test = [np.load(fname) for fname in full_npz_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "baa89e2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T09:58:36.135150Z",
     "start_time": "2021-08-04T09:58:08.548457Z"
    }
   },
   "outputs": [],
   "source": [
    "images = list()\n",
    "images += [npz['arr_0'] for npz in data_all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45f09b65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T09:58:36.151153Z",
     "start_time": "2021-08-04T09:58:36.137151Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = list()\n",
    "labels += [npz['arr_1'] for npz in data_all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "562ac213",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T09:58:36.167153Z",
     "start_time": "2021-08-04T09:58:36.153153Z"
    }
   },
   "outputs": [],
   "source": [
    "# images_val = list()\n",
    "# images_val += [npz['arr_0'] for npz in data_all_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "308c41f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T09:58:36.183153Z",
     "start_time": "2021-08-04T09:58:36.169152Z"
    }
   },
   "outputs": [],
   "source": [
    "# labels_val = list()\n",
    "# labels_val += [npz['arr_1'] for npz in data_all_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20e28f2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T09:58:50.343734Z",
     "start_time": "2021-08-04T09:58:36.186158Z"
    }
   },
   "outputs": [],
   "source": [
    "images_test = list()\n",
    "images_test += [npz['arr_0'] for npz in data_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94524029",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T09:58:50.359736Z",
     "start_time": "2021-08-04T09:58:50.345736Z"
    }
   },
   "outputs": [],
   "source": [
    "labels_test = list()\n",
    "labels_test += [npz['arr_1'] for npz in data_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cda4dc",
   "metadata": {},
   "source": [
    "## Light Augmenter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0575594f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T09:58:50.375737Z",
     "start_time": "2021-08-04T09:58:50.362738Z"
    }
   },
   "outputs": [],
   "source": [
    "def adjust_gamma(img):\n",
    "    ratio = 0.5 / 1\n",
    "    if ratio >= 1:\n",
    "        print(\"Image already bright enough\")\n",
    "        return img\n",
    "\n",
    "    # Otherwise, adjust brightness to get the target brightness\n",
    "    return cv2.convertScaleAbs(img, alpha = 1 / ratio, beta = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43053a92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T09:58:50.390736Z",
     "start_time": "2021-08-04T09:58:50.378739Z"
    }
   },
   "outputs": [],
   "source": [
    "def blur(image):\n",
    "    return cv2.blur(image,(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "147a0262",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T09:58:50.421736Z",
     "start_time": "2021-08-04T09:58:50.392736Z"
    }
   },
   "outputs": [],
   "source": [
    "class CustomAugmentation(object):\n",
    "    \"\"\" Defines a custom augmentation class\"\"\"\n",
    "    \n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    \n",
    "    def __init__(self, erosion = False, dilation = False, light = False,\n",
    "                       sharpness = False, blur = False):\n",
    "        self.erosion = erosion\n",
    "        self.dilation = dilation\n",
    "        self.light = light\n",
    "        self.sharpness = sharpness\n",
    "        self.blur = blur\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        \n",
    "        randomNumber = np.random.random()\n",
    "        \n",
    "        # Erosion and dilation are never applied together\n",
    "        \n",
    "        if randomNumber < 0.9:\n",
    "            pass\n",
    "        elif randomNumber < 0.95:\n",
    "            if self.erosion == True:\n",
    "                # Apply erosion 5% of the time if True\n",
    "                img = cv2.erode(img,CustomAugmentation.kernel,iterations = 1)\n",
    "                img = img.reshape(120,120,3)\n",
    "                \n",
    "        elif self.dilation == True:\n",
    "                # Apply dilation 5% of the time if True\n",
    "            img = cv2.dilate(img, CustomAugmentation.kernel,iterations = 1)\n",
    "            img = img.reshape(120,120,3)\n",
    "                \n",
    "        elif self.light == True:\n",
    "            img = adjust_gamma(img)\n",
    "            img = img.reshape(120,120,3)\n",
    "\n",
    "        elif self.sharpness == True:\n",
    "            kernel = np.array([[0, -1, 0], [-1, 5,-1], [0, -1, 0]])\n",
    "            img = cv2.filter2D(img, -1, kernel)\n",
    "            img = img.reshape(120, 120, 3)\n",
    "            \n",
    "        elif self.blur == True:\n",
    "            img = blur(img) if np.random.random()>0.5 else add_sharpness(img)\n",
    "            img = img.reshape(120, 120, 3)\n",
    "                \n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ed2518",
   "metadata": {},
   "source": [
    "# Before all, define a custom activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a87c4160",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T09:58:50.437736Z",
     "start_time": "2021-08-04T09:58:50.423738Z"
    }
   },
   "outputs": [],
   "source": [
    "# custom activation function\n",
    "def custom_activation(output):\n",
    "    logexpsum = backend.sum(backend.exp(output), axis=-1, keepdims=True)\n",
    "    result = logexpsum / (logexpsum + 1.0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74bf213",
   "metadata": {},
   "source": [
    "# Defining the models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c801ae4d",
   "metadata": {},
   "source": [
    "## Discriminator (standalone supervised and unsupervised discriminator models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5992cb07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T09:58:50.467735Z",
     "start_time": "2021-08-04T09:58:50.439736Z"
    }
   },
   "outputs": [],
   "source": [
    "# define the standalone supervised and unsupervised discriminator models\n",
    "def define_discriminator(in_shape=(120, 120, 3), n_classes=14):\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "# image input\n",
    "    in_image = Input(shape=in_shape)\n",
    "\n",
    "# #downsample\n",
    "    c1 = Conv2D(64, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(in_image)\n",
    "    c1 = LeakyReLU(alpha=0.4)(c1)\n",
    "    c1 = BatchNormalization(axis=1)(c1)\n",
    "    \n",
    "    c1 = Conv2D(64, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(c1)\n",
    "    c1 = LeakyReLU(alpha=0.4)(c1)\n",
    "    c1 = BatchNormalization(axis=1)(c1)\n",
    "    \n",
    "    c1 = MaxPooling2D(pool_size = (2,2))(c1)\n",
    "    c1 = Dropout(0.2)(c1)\n",
    "    \n",
    "    c1 = Conv2D(128, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(c1)\n",
    "    c1 = LeakyReLU(alpha=0.4)(c1)\n",
    "    c1 = BatchNormalization(axis=1)(c1)\n",
    "    \n",
    "    c1 = Conv2D(128, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(c1)\n",
    "    c1 = LeakyReLU(alpha=0.4)(c1)\n",
    "    c1 = BatchNormalization(axis=1)(c1)\n",
    "    \n",
    "    c1 = MaxPooling2D(pool_size = (2,2))(c1)\n",
    "    c1 = Dropout(0.2)(c1)\n",
    "    \n",
    "    c1 = Conv2D(256, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(c1)\n",
    "    c1 = LeakyReLU(alpha=0.4)(c1)\n",
    "    c1 = BatchNormalization(axis=1)(c1)\n",
    "    \n",
    "    c1 = Conv2D(256, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(c1)\n",
    "    c1 = LeakyReLU(alpha=0.4)(c1)\n",
    "    c1 = BatchNormalization(axis=1)(c1)\n",
    "    \n",
    "#     c1 = MaxPooling2D(pool_size = (2,2))(c1)\n",
    "    c1 = Dropout(0.2)(c1)\n",
    "    \n",
    "# flatten feature maps\n",
    "    fe = Flatten()(c1)\n",
    "#     fe = (Dense(256))(fe)\n",
    "#     fe = LeakyReLU(alpha=0.4)(fe)\n",
    "#     fe = BatchNormalization(axis=1)(fe)\n",
    "# dropout\n",
    "    fe = Dropout(0.2)(fe)\n",
    "    \n",
    "# output layer nodes\n",
    "    fe = Dense(n_classes, kernel_initializer=init)(fe)\n",
    "# supervised output\n",
    "    c_out_layer = Activation('softmax')(fe)\n",
    "# define and compile supervised discriminator model\n",
    "    c_model = Model(in_image, c_out_layer)\n",
    "    c_model.compile(loss='sparse_categorical_crossentropy', optimizer=Adagrad(lr=0.0005), metrics=['accuracy']) #beta_1=0.5\n",
    "# unsupervised output\n",
    "    d_out_layer = Lambda(custom_activation)(fe)\n",
    "# define and compile unsupervised discriminator model\n",
    "    d_model = Model(in_image, d_out_layer)\n",
    "    d_model.compile(loss='mse', optimizer=Adam(lr=0.0002, beta_1=0.5))\n",
    "    return d_model, c_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f5d0f3",
   "metadata": {},
   "source": [
    "## Classifier (Define the standalone classifier model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "de9b20b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T09:58:50.498736Z",
     "start_time": "2021-08-04T09:58:50.469746Z"
    }
   },
   "outputs": [],
   "source": [
    "def define_standalone_classifier(in_shape=(120,120,3), n_classes=14):\n",
    "    # image input\n",
    "    in_image = Input(shape=in_shape)\n",
    "    # Conv Layer and downsample\n",
    "    fe = Conv2D(32, (3,3))(in_image)\n",
    "    fe = LeakyReLU(alpha=0)(fe)\n",
    "    fe = BatchNormalization(axis=1)(fe)\n",
    "    fe = MaxPooling2D(pool_size = (2,2))(fe)\n",
    "   # Conv Layer and downsample\n",
    "    fe = Conv2D(32, (3,3))(fe)\n",
    "    fe = LeakyReLU(alpha=0)(fe)\n",
    "    fe = MaxPooling2D(pool_size = (2,2))(fe)\n",
    "    # Conv Layer and downsample\n",
    "    fe = Conv2D(64, (3,3))(fe)\n",
    "    fe = LeakyReLU(alpha=0)(fe)\n",
    "    fe = BatchNormalization(axis=1)(fe)\n",
    "    fe = MaxPooling2D(pool_size = (2,2))(fe)\n",
    "    # Conv Layer and downsample\n",
    "    fe = Conv2D(128, (3,3))(fe)\n",
    "    fe = LeakyReLU(alpha=0)(fe)\n",
    "    fe = MaxPooling2D(pool_size = (2,2))(fe)\n",
    "    # flatten feature maps\n",
    "    fe = Flatten()(fe)\n",
    "    # dropout\n",
    "    fe = Dense(128)(fe)\n",
    "    fe = LeakyReLU(alpha=0)(fe)\n",
    "    fe = Dropout(0.5)(fe)\n",
    "    # output layer nodes\n",
    "    fe = Dense(n_classes)(fe)\n",
    "    # supervised output\n",
    "    c_out_layer = Activation('sigmoid')(fe)\n",
    "    # define and compile standalone classifier model\n",
    "    c_model = Model(in_image, c_out_layer)\n",
    "    c_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return c_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57338a5a",
   "metadata": {},
   "source": [
    "##  Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c650df87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T09:58:50.530736Z",
     "start_time": "2021-08-04T09:58:50.506739Z"
    }
   },
   "outputs": [],
   "source": [
    "# define the standalone generator model\n",
    "def define_generator(latent_dim):\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    #image generator input\n",
    "    in_lat = Input(shape=(latent_dim,))\n",
    "# foundation for 120x120 image (the 15*15 is the 1/8 of the size of the image. metric given by the book)\n",
    "    n_nodes = 128 * 15 * 15\n",
    "    gen = Dense(n_nodes)(in_lat)\n",
    "    gen = LeakyReLU(alpha=0.2)(gen)\n",
    "    gen = Reshape((15, 15, 128))(gen)\n",
    "    # upsample to 30x30\n",
    "    gen = Conv2DTranspose(32, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(gen)\n",
    "    gen = BatchNormalization(axis=1)(gen)\n",
    "    gen = LeakyReLU(alpha=0.4)(gen)\n",
    "#upsample to 60x60\n",
    "    gen = Conv2DTranspose(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(gen)\n",
    "    gen = BatchNormalization(axis=1)(gen)\n",
    "    gen = LeakyReLU(alpha=0.4)(gen)\n",
    "# #upsample to 120x120\n",
    "    gen = Conv2DTranspose(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(gen)\n",
    "    gen = BatchNormalization(axis=1)(gen)\n",
    "    gen = LeakyReLU(alpha=0.4)(gen)\n",
    "# output\n",
    "    out_layer = Conv2D(3, (15, 15), activation='tanh', padding='same', kernel_initializer=init)(gen)\n",
    "# define model \n",
    "    model = Model(in_lat, out_layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7634c24f",
   "metadata": {},
   "source": [
    "### combined generator and discriminator model (for updating the generator) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "857dba0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T09:58:50.546737Z",
     "start_time": "2021-08-04T09:58:50.535738Z"
    }
   },
   "outputs": [],
   "source": [
    "# define the combined generator and discriminator model, for updating the generator\n",
    "def define_gan(g_model, d_model):\n",
    "# make weights in the discriminator not trainable\n",
    "    d_model.trainable = False\n",
    "# connect image output from generator as input to discriminator\n",
    "    gan_output = d_model(g_model.output)\n",
    "# define gan model as taking noise and outputting a classification\n",
    "    model = Model(g_model.input, gan_output)\n",
    "# compile model\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='mse', optimizer=opt)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57a600f",
   "metadata": {},
   "source": [
    "# select a supervised subset of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1f691938",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T09:58:50.561736Z",
     "start_time": "2021-08-04T09:58:50.548738Z"
    }
   },
   "outputs": [],
   "source": [
    "def select_supervised_samples(dataset, n_samples=5000, n_classes=14):\n",
    "    X, y = dataset\n",
    "    X_list, y_list = list(), list()\n",
    "    n_per_class = int(n_samples / n_classes)\n",
    "    for n in range (0, 4):\n",
    "        for i in range(n_classes):\n",
    "            # get all images for this class\n",
    "            X_with_class = [X[n]][[y[n]] == i]\n",
    "            # choose random instances\n",
    "            ix = randint(0, len(X_with_class), n_per_class)\n",
    "            # add to list\n",
    "            [X_list.append(X_with_class[j]) for j in ix]\n",
    "            [y_list.append(i) for j in ix]\n",
    "    return asarray(X_list), asarray(y_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c9eac8ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T09:58:50.576736Z",
     "start_time": "2021-08-04T09:58:50.564739Z"
    }
   },
   "outputs": [],
   "source": [
    "def select_supervised_samples2(dataset, n_samples=5000, n_classes=14):\n",
    "    X, y = dataset\n",
    "    X_list, y_list = list(), list()\n",
    "    n_per_class = int(n_samples / n_classes)\n",
    "    for n in range (0, 2):\n",
    "        for i in range(n_classes):\n",
    "            # get all images for this class\n",
    "            X_with_class = [X[n]][[y[n]] == i]\n",
    "            # choose random instances\n",
    "            ix = randint(0, len(X_with_class), n_per_class)\n",
    "            # add to list\n",
    "            [X_list.append(X_with_class[j]) for j in ix]\n",
    "            [y_list.append(i) for j in ix]\n",
    "    return asarray(X_list), asarray(y_list) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edcc739",
   "metadata": {},
   "source": [
    "# Select random samples from the supervised dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e408beb8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T09:58:50.592735Z",
     "start_time": "2021-08-04T09:58:50.579739Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_real_samples(X, y, n_samples):\n",
    "# split into images and labels\n",
    "    ima = X\n",
    "    lab = y\n",
    "# choose random instances\n",
    "    ix = randint(0, ima.shape[0], n_samples)\n",
    "# select images and labels\n",
    "    X, labels = ima[ix], lab[ix]\n",
    "# generate class labels\n",
    "    y = ones((n_samples, 1))\n",
    "    return [X, lab], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c63124c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T09:58:50.608734Z",
     "start_time": "2021-08-04T09:58:50.595739Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_real_samples2(x, y, n_samples):\n",
    "# split into images and labels\n",
    "    ix = randint(0, x[0].shape[0], n_samples)\n",
    "    im_list = list()\n",
    "    lab_list = list()\n",
    "# select images and labels\n",
    "    for n in range (0, 4): \n",
    "        for i in x[n][ix]:\n",
    "            im_list.append(i)\n",
    "        for c in y[n][ix]:\n",
    "            lab_list.append(c)\n",
    "# generate class labels\n",
    "    y = ones((n_samples*4, 1))\n",
    "    return [asarray(im_list), asarray(lab_list)], y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf00a2b6",
   "metadata": {},
   "source": [
    "## generate points in latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4bb25002",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T09:58:50.623737Z",
     "start_time": "2021-08-04T09:58:50.611737Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_latent_points(latent_dim, n_samples):\n",
    "\t# generate points in the latent space\n",
    "\tz_input = randn(latent_dim * n_samples)\n",
    "\t# reshape into a batch of inputs for the network\n",
    "\tz_input = z_input.reshape(n_samples, latent_dim)\n",
    "\treturn z_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523141b2",
   "metadata": {},
   "source": [
    "## Generate the fake images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5e84c23f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T09:58:50.638734Z",
     "start_time": "2021-08-04T09:58:50.626739Z"
    }
   },
   "outputs": [],
   "source": [
    "# use the generator to generate n fake examples, with class labels\n",
    "def generate_fake_samples(generator, latent_dim, n_samples):\n",
    "# generate points in latent space\n",
    "    z_input = generate_latent_points(latent_dim, n_samples)\n",
    "# predict outputs\n",
    "    images = generator.predict(z_input)\n",
    "# create class labels\n",
    "    y = zeros((n_samples, 1))\n",
    "    return images, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e87f09",
   "metadata": {},
   "source": [
    "# save as a plot and save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b986b6b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T09:58:50.654734Z",
     "start_time": "2021-08-04T09:58:50.640736Z"
    }
   },
   "outputs": [],
   "source": [
    "def summarize_performance(step, g_model, c_model, latent_dim, dataset2, max_acc_c,folder, n_samples=100):\n",
    "    \n",
    "    # prepare fake examples\n",
    "    X, _ = generate_fake_samples(g_model, latent_dim, n_samples)\n",
    "    # scale from [-1,1] to [0,1]\n",
    "    X = (X + 1) / 2.0\n",
    "    # plot images\n",
    "    for i in range(9):\n",
    "        # define subplot\n",
    "        plt.subplot(3, 3, 1 + i)\n",
    "        # turn off axis\n",
    "        plt.axis('off')\n",
    "        # plot raw pixel data\n",
    "        plt.imshow(X[i, :, :, 0])\n",
    "    # save plot to file\n",
    "    filename1 = folder+'/generated_plot_%04d.png' % (step+1)\n",
    "    plt.savefig(filename1)\n",
    "    plt.close()\n",
    "    # evaluate the classifier model\n",
    "    X, y = dataset2\n",
    "    \n",
    "#     for n in range(0, 4):\n",
    "    for n in range(0,2):\n",
    "        _, acc = c_model.evaluate(X[n], y[n], verbose=0)\n",
    "        if acc>max_acc_c:\n",
    "            print('Best acc so far! best_acc_c = %.3f%%' % (acc * 300))           \n",
    "            max_acc_c = acc\n",
    "            c_model.save(folder+'/c_model_best.h5')\n",
    "        else:\n",
    "            print('Best acc did not improve! best_acc_c = %.3f%%' % (max_acc_c * 300))\n",
    "        \n",
    "    #print('Classifier Accuracy: %.3f%%' % (acc * 100))\n",
    "    # save the generator model\n",
    "    filename2 = folder+'/g_model_%04d.h5' % (step+1)\n",
    "    g_model.save(filename2)\n",
    "    # save the classifier model\n",
    "    filename3 = folder+'/c_model_%04d.h5' % (step+1)\n",
    "    c_model.save(filename3)\n",
    "    print('>Saved: %s, %s, and %s' % (filename1, filename2, filename3))  \n",
    "    \n",
    "    return max_acc_c   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866dd7c8",
   "metadata": {},
   "source": [
    "# Training the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5d8c87b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T09:58:50.669735Z",
     "start_time": "2021-08-04T09:58:50.656737Z"
    }
   },
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(monitor = 'accuracy', \n",
    "                          min_delta = 0, \n",
    "                          patience = 5,\n",
    "                          verbose = 1,\n",
    "                          restore_best_weights = True)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor = 'accuracy',\n",
    "                              factor = 0.2,\n",
    "                              patience = 6,\n",
    "                              verbose = 1,\n",
    "                              min_delta = 0.0001)\n",
    "\n",
    "# we put our call backs into a callback list\n",
    "callbacks = [earlystop, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "725ef765",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T09:58:50.684734Z",
     "start_time": "2021-08-04T09:58:50.671737Z"
    }
   },
   "outputs": [],
   "source": [
    "preprocesor = CustomAugmentation(erosion=False, dilation= False, light= True, sharpness = False, blur = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a2eb3b9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T09:58:50.716734Z",
     "start_time": "2021-08-04T09:58:50.686737Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(g_model, d_model, c_model, gan_model, dataset, latent_dim,folder,n_samples, n_epochs=50, n_batch=100, with_aug=True):\n",
    "    \n",
    "    max_acc_c =0\n",
    "    # select supervised dataset\n",
    "    X_sup, y_sup = select_supervised_samples(dataset,n_samples)\n",
    "    \n",
    "    X_val, y_val = select_supervised_samples2(dataset,n_samples)\n",
    "    \n",
    "    print(X_sup.shape, y_sup.shape)\n",
    "    # calculate the number of batches per training epoch\n",
    "    bat_per_epo = int(dataset[0][0].shape[0] / n_batch)\n",
    "    # calculate the number of training iterations\n",
    "    n_steps = bat_per_epo * n_epochs\n",
    "    # calculate the size of half a batch of samples\n",
    "    half_batch = int(n_batch / 2)\n",
    "    \n",
    "    if(with_aug):\n",
    "        train_datagen = ImageDataGenerator( preprocessing_function = preprocesor) #rotation_range = 10,\n",
    "                             #zoom_range = 0.3, width_shift_range = 0.2, height_shift_range = 0.2 )\n",
    "\n",
    "    else:\n",
    "        train_datagen = ImageDataGenerator(\n",
    "                horizontal_flip=False)  \n",
    "        \n",
    "        \n",
    "    print('n_epochs=%d, n_batch=%d, 1/2=%d, b/e=%d, steps=%d' % (n_epochs, n_batch, half_batch, bat_per_epo, n_steps))\n",
    "    # manually enumerate epochs, get one \n",
    "    for i in range(n_epochs):\n",
    "        print(\"Epoch {}/{}\".format(i, n_epochs))\n",
    "        flow_iter = train_datagen.flow(X_sup, y_sup, half_batch) #this is an enumerator for random half-batches\n",
    "        with tqdm(total = bat_per_epo, position = 0, leave=True) as progress_bar:\n",
    "            for j, [Xsup_real, ysup_real] in enumerate(flow_iter):\n",
    "                if j >= bat_per_epo:\n",
    "                    break #the enumerator itself will run forever, stop on expected number of batches\n",
    "                progress_bar.update(1)\n",
    "                \n",
    "                c_model.fit(Xsup_real, ysup_real, validation_data = (X_val, y_val), callbacks = callbacks, verbose=0)\n",
    "                \n",
    "                # update unsupervised discriminator (d)\n",
    "                [X_real, _], y_real = generate_real_samples2(images, labels, half_batch) #generate real, but not labeled samples for the discriminator\n",
    "                d_model.train_on_batch(X_real, y_real)\n",
    "                \n",
    "                X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "                d_model.train_on_batch(X_fake, y_fake)\n",
    "                \n",
    "                # update generator (g)\n",
    "                X_gan, y_gan = generate_latent_points(latent_dim, n_batch), ones((n_batch, 1))\n",
    "                gan_model.train_on_batch(X_gan, y_gan)\n",
    "\n",
    "        max_acc_c= summarize_performance(i, g_model, c_model, latent_dim, dataset2, max_acc_c, folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "60972713",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T09:58:50.731736Z",
     "start_time": "2021-08-04T09:58:50.718737Z"
    }
   },
   "outputs": [],
   "source": [
    "# # train the standalone classifier\n",
    "# def train_stand_alone_c(c_model, dataset, folder, n_epochs=50, n_batch=100, n_samples=100,n_classes=14,with_aug=True):\n",
    "#     max_acc_c = 0\n",
    "#     # select supervised dataset\n",
    "#     X_sup, y_sup = select_supervised_samples(dataset,n_samples,n_classes)\n",
    "    \n",
    "#     print(X_sup.shape, y_sup.shape)\n",
    "#     # calculate the number of batches per training epoch\n",
    "#     bat_per_epo = int(X_sup.shape[0] / n_batch)\n",
    "#     # calculate the number of training iterations\n",
    "#     n_steps = bat_per_epo * n_epochs\n",
    "#     # calculate the size of half a batch of samples\n",
    "#     half_batch = int(n_batch / 2)\n",
    "#     print('n_epochs=%d, n_batch=%d, 1/2=%d, b/e=%d, steps=%d' % (n_epochs, n_batch, half_batch, bat_per_epo, n_steps))\n",
    "#     # manually enumerate epochs\n",
    "    \n",
    "#     test_datagen = ImageDataGenerator()\n",
    "    \n",
    "#     if(with_aug):\n",
    "#         train_datagen = ImageDataGenerator(\n",
    "#                 rotation_range = 20,\n",
    "#                 width_shift_range = 0.1,\n",
    "#                 height_shift_range = 0.1,\n",
    "#                 shear_range=0.2,\n",
    "#                 zoom_range=0.2)\n",
    "#     else:\n",
    "#         train_datagen = ImageDataGenerator(\n",
    "#                 horizontal_flip=False)\n",
    "    \n",
    "#     train_dgi = train_datagen.flow(X_sup, y_sup, n_batch)\n",
    "#     X_all, y_all = dataset \n",
    "#     test_dgi = test_datagen.flow(X_all, y_all, 64)\n",
    "#     print(test_dgi.n)\n",
    "    \n",
    "#     csv_logger = CSVLogger(folder +'/training.log')\n",
    "#     check_point = ModelCheckpoint(folder+\"/c_model_best.h5\", monitor = \"val_acc\", verbose =1, save_best_only = True,mode = \"max\") \n",
    "    \n",
    "#     c_model.fit_generator(train_dgi,\n",
    "#             steps_per_epoch=bat_per_epo,\n",
    "#             epochs=n_epochs,\n",
    "#             validation_data = test_dgi,\n",
    "#             validation_steps = test_dgi.n//(4*64),\n",
    "#             callbacks = [csv_logger, check_point])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ed4b1e",
   "metadata": {},
   "source": [
    "## size of the latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c951343a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T09:58:50.746736Z",
     "start_time": "2021-08-04T09:58:50.734736Z"
    }
   },
   "outputs": [],
   "source": [
    "# size of the latent space\n",
    "latent_dim = 100\n",
    "#number of classes\n",
    "n_classes=14\n",
    "#number of labled samples\n",
    "#arr_n_samples = [50,100,150,200,500,700,1000,2000,3000,4000,5000]\n",
    "arr_n_samples = [3000]\n",
    " #batch sizes (for standalone classifier)\n",
    "#n_batches = [8,8,8,16,16,32,32,32,32,64,64] \n",
    "n_batches = [120]  \n",
    "\n",
    "stand_alone_flag = False #Change this for SGAN/STANDALONE\n",
    "augmentation_flag = True #Change this for AUG/NO_AUG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aee74b6",
   "metadata": {},
   "source": [
    "## Assigning the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9589b8ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T09:58:50.762737Z",
     "start_time": "2021-08-04T09:58:50.748739Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "93b1a555",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T09:58:50.778734Z",
     "start_time": "2021-08-04T09:58:50.765738Z"
    }
   },
   "outputs": [],
   "source": [
    "# dataset_val = images_val, labels_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3a8d0af5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T09:58:50.793734Z",
     "start_time": "2021-08-04T09:58:50.780735Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset2 = images_test, labels_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa617e8",
   "metadata": {},
   "source": [
    "## train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "acedfbff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T10:32:53.825747Z",
     "start_time": "2021-08-04T09:58:50.795735Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/99 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11984, 120, 120, 3) (11984,)\n",
      "n_epochs=50, n_batch=100, 1/2=50, b/e=99, steps=4950\n",
      "Epoch 0/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 99/99 [23:54<00:00, 14.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best acc so far! best_acc_c = 21.489%\n",
      "Best acc did not improve! best_acc_c = 21.489%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/99 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: testSGAN_with_aug3000/generated_plot_0001.png, testSGAN_with_aug3000/g_model_0001.h5, and testSGAN_with_aug3000/c_model_0001.h5\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 99/99 [08:45<00:00,  5.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best acc did not improve! best_acc_c = 21.489%\n",
      "Best acc did not improve! best_acc_c = 21.489%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▊                                                                                  | 1/99 [00:00<00:14,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: testSGAN_with_aug3000/generated_plot_0002.png, testSGAN_with_aug3000/g_model_0002.h5, and testSGAN_with_aug3000/c_model_0002.h5\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███████▌                                                                           | 9/99 [00:46<07:44,  5.16s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-344b7c7093a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[1;31m# train model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgan_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfolder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marr_n_samples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwith_aug\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maugmentation_flag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-38-09797b17bbb7>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(g_model, d_model, c_model, gan_model, dataset, latent_dim, folder, n_samples, n_epochs, n_batch, with_aug)\u001b[0m\n\u001b[0;32m     46\u001b[0m                 \u001b[1;31m# update generator (g)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m                 \u001b[0mX_gan\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_gan\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_latent_points\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m                 \u001b[0mgan_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_gan\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_gan\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[0mmax_acc_c\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0msummarize_performance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_acc_c\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfolder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-latest\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[0;32m   1728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1729\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1730\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1731\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1732\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-latest\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mreset_metrics\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1667\u001b[0m     \"\"\"\n\u001b[0;32m   1668\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1669\u001b[1;33m       \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1671\u001b[0m   def train_on_batch(self,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-latest\\lib\\site-packages\\tensorflow\\python\\keras\\metrics.py\u001b[0m in \u001b[0;36mreset_states\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    251\u001b[0m     \u001b[0mwhen\u001b[0m \u001b[0ma\u001b[0m \u001b[0mmetric\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mevaluated\u001b[0m \u001b[0mduring\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m     \"\"\"\n\u001b[1;32m--> 253\u001b[1;33m     \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mabc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-latest\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-latest\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[1;34m(tuples)\u001b[0m\n\u001b[0;32m   3704\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly_outside_functions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3705\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtuples\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3706\u001b[1;33m       \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3707\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3708\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-latest\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36massign\u001b[1;34m(self, value, use_locking, name, read_value)\u001b[0m\n\u001b[0;32m    890\u001b[0m              \"shape %s are incompatible\") %\n\u001b[0;32m    891\u001b[0m             (tensor_name, self._shape, value_tensor.shape))\n\u001b[1;32m--> 892\u001b[1;33m       assign_op = gen_resource_variable_ops.assign_variable_op(\n\u001b[0m\u001b[0;32m    893\u001b[0m           self.handle, value_tensor, name=name)\n\u001b[0;32m    894\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mread_value\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-latest\\lib\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py\u001b[0m in \u001b[0;36massign_variable_op\u001b[1;34m(resource, value, name)\u001b[0m\n\u001b[0;32m    138\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m    141\u001b[0m         _ctx, \"AssignVariableOp\", name, resource, value)\n\u001b[0;32m    142\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if stand_alone_flag:\n",
    "    for i in range(np.size(arr_n_samples ,0)):\n",
    "        if augmentation_flag:\n",
    "            folder = \"testStandAlone_with_aug\"+str(arr_n_samples[i])\n",
    "        else:\n",
    "            folder = \"testStandAlone_without_aug\"+str(arr_n_samples[i])\n",
    "        if not os.path.exists(\"./\"+folder+\"/\"):\n",
    "                        os.makedirs(\"./\"+folder+\"/\")\n",
    "        \n",
    "       \n",
    "        # create the standalone classifier\n",
    "        c_model = define_standalone_classifier(n_classes=n_classes)\n",
    "    \n",
    "        # load image data\n",
    "        dataset = images, labels\n",
    "        # train model\n",
    "        n_batch = n_batches[i]\n",
    "        train_stand_alone_c(c_model, dataset, folder, n_samples=arr_n_samples[i],n_epochs=200, n_batch=n_batch, n_classes=n_classes, with_aug=augmentation_flag)\n",
    "\n",
    "else:   \n",
    "    for i in range(np.size(arr_n_samples ,0)):\n",
    "        if augmentation_flag:\n",
    "            folder = \"testSGAN_with_aug\"+str(arr_n_samples[i])\n",
    "        else:\n",
    "            folder = \"testSGAN_without_aug\"+str(arr_n_samples[i]) \n",
    "        \n",
    "        if not os.path.exists(\"./\"+folder+\"/\"):\n",
    "                        os.makedirs(\"./\"+folder+\"/\")\n",
    "        \n",
    "        # create the discriminator models\n",
    "        d_model, c_model = define_discriminator()\n",
    "        # create the generator\n",
    "        g_model = define_generator(latent_dim)\n",
    "        # create the gan\n",
    "        gan_model = define_gan(g_model, d_model)\n",
    "        # load image data\n",
    "        dataset = images, labels\n",
    "        # train model\n",
    "        train(g_model, d_model, c_model, gan_model, dataset, latent_dim, folder, n_samples=arr_n_samples[i], with_aug = augmentation_flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bc071c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e714ffc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
